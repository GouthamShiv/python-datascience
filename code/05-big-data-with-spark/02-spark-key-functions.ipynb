{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back](./01-spark-overview.ipynb)\n",
    "\n",
    "---\n",
    "## `Spark - Key Functions`\n",
    "\n",
    "- Map vs. FlatMap\n",
    "- PairRDD\n",
    "- Reduce by Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Initial Setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input.txt\n",
    "hello world\n",
    "another line\n",
    "yet another line\n",
    "yet another new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/goutham/opt/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/06/13 23:39:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark as ps\n",
    "\n",
    "spark = ps.sql.SparkSession.builder.master(\n",
    "    'local[*]').appName('spark-lecture').getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Map vs. FlatMap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map is a function, meaning a transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Count the number of lines in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('input.txt').map(lambda x: x.split()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the lines in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hello', 'world'],\n",
       " ['another', 'line'],\n",
       " ['yet', 'another', 'line'],\n",
       " ['yet', 'another', 'new', 'line']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('input.txt').map(lambda x: x.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello world', 'another line', 'yet another line', 'yet another new line']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('input.txt')\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FlatMap to split and file content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " 'world',\n",
       " 'another',\n",
       " 'line',\n",
       " 'yet',\n",
       " 'another',\n",
       " 'line',\n",
       " 'yet',\n",
       " 'another',\n",
       " 'new',\n",
       " 'line']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('input.txt').flatMap(lambda x: x.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map and FlatMap are both transformations, but Map can return a list of list, where as a FlatMap will return flattened list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PairRDD`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of now, we have seen how to aggregate values across an RDD. If we have an RDD containing sales transactions, we can find the total revenue across all transactions.\n",
    "\n",
    "Q. Using the following sales data, find the total revenue across all transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sales.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile sales.txt\n",
    "#ID   Date          Store   State   Product   Amount\n",
    "101   11/13/2014    100     WA      331       300.00\n",
    "104   11/18/2014    700     OR      329       450.00\n",
    "102   11/15/2014    203     CA      321       200.00\n",
    "106   11/19/2014    202     CA      331       330.00\n",
    "103   11/17/2014    101     WA      373       750.00\n",
    "105   11/19/2014    202     CA      321       200.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#ID   Date          Store   State   Product   Amount',\n",
       " '101   11/13/2014    100     WA      331       300.00']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('sales.txt').take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['106   11/19/2014    202     CA      331       330.00',\n",
       " '105   11/19/2014    202     CA      321       200.00']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('sales.txt').top(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the contents in a lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#ID', 'Date', 'Store', 'State', 'Product', 'Amount'],\n",
       " ['101', '11/13/2014', '100', 'WA', '331', '300.00']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('sales.txt').map(lambda x: x.split()).take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove the #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['101', '11/13/2014', '100', 'WA', '331', '300.00'],\n",
       " ['104', '11/18/2014', '700', 'OR', '329', '450.00']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('sales.txt') \\\n",
    ".map(lambda x: x.split()) \\\n",
    ".filter(lambda x: not x[0].startswith('#')) \\\n",
    ".take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pick the last field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['300.00', '450.00']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('sales.txt') \\\n",
    "    .map(lambda x: x.split()) \\\n",
    "    .filter(lambda x: not x[0].startswith('#')) \\\n",
    "    .map(lambda x: x[-1]) \\\n",
    "    .take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert to float and then sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2230.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('sales.txt') \\\n",
    "    .map(lambda x: x.split()) \\\n",
    "    .filter(lambda x: not x[0].startswith('#')) \\\n",
    "    .map(lambda x: float(x[-1])) \\\n",
    "    .sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Reduce By Key`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Calculate revenue per state?\n",
    "\n",
    "- Instead of creating a sequence of revenue numbers, we can create tuples of state and revenues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('WA', 300.0),\n",
       " ('OR', 450.0),\n",
       " ('CA', 200.0),\n",
       " ('CA', 330.0),\n",
       " ('WA', 750.0),\n",
       " ('CA', 200.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('sales.txt')\\\n",
    "  .map(lambda x: x.split())\\\n",
    "    .filter(lambda x: not x[0].startswith('#'))\\\n",
    "    .map(lambda x: (x[-3], float(x[-1])))\\\n",
    "      .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, we can use reduceByKey to add them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CA', 730.0), ('WA', 1050.0), ('OR', 450.0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('sales.txt')\\\n",
    "  .map(lambda x: x.split())\\\n",
    "    .filter(lambda x: not x[0].startswith('#'))\\\n",
    "    .map(lambda x: (x[-3], float(x[-1])))\\\n",
    "      .reduceByKey(lambda amount1, amount2: amount1 + amount2)\\\n",
    "        .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ReduceByMap is now treating the first element in the tuple as a **key**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Find the state with the highest revenue.\n",
    "\n",
    "- We can either use the action `top` or the transformation `sortBy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('WA', 1050.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('sales.txt')\\\n",
    "  .map(lambda x: x.split())\\\n",
    "  .filter(lambda x: not x[0].startswith('#'))\\\n",
    "  .map(lambda x: (x[-3], float(x[-1])))\\\n",
    "  .reduceByKey(lambda amount1, amount2: amount1 + amount2)\\\n",
    "  .sortBy(lambda state_amount: state_amount[1], ascending = False)\\\n",
    "  .take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. What does `reduceByKey` do?\n",
    "\n",
    "- `reduceByKey` only works on RDDs made up of 2-tuples.\n",
    "- `reduceByKey` works as both a reducer and a combiner.\n",
    "- It requires that the operation is associative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Word Count`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Implement word count in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create some input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wc.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile wc.txt\n",
    "hello world\n",
    "another line\n",
    "this is another line\n",
    "this is the last line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Count the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('world', 1),\n",
       " ('line', 3),\n",
       " ('this', 2),\n",
       " ('is', 2),\n",
       " ('last', 1),\n",
       " ('hello', 1),\n",
       " ('another', 2),\n",
       " ('the', 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('wc.txt')\\\n",
    "  .flatMap(lambda x: x.split())\\\n",
    "  .map(lambda word: (word, 1))\\\n",
    "  .reduceByKey(lambda count1, count2: count1 + count2)\\\n",
    "  .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Conclusion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "[next]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b4484ae063bf9ef0d5115063857dd0e382a2c73ed49a11a000ca56af03302b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
