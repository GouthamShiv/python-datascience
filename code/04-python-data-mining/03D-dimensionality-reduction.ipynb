{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back](./03C-association-and-correlation.ipynb)\n",
    "\n",
    "---\n",
    "## `Dimensionality Reduction`\n",
    "\n",
    "A very common issue with **dimensionality** is with having a lot of **dimensions** is called as _curse of dimensionality_\n",
    "\n",
    "> _curse of dimensionality:_\n",
    ">\n",
    "> As a number of features or dimensions grows, the amount of data that we need to generalize accurately grows exponentially\n",
    "\n",
    "So, if we have more features, meaning we have more columns in our DataFrame then we'll need a lot more rules, data-points to counter this sparsity that you get from the growth of the feature.\n",
    "\n",
    "That's why we want to do our best to reduce the features and for that, `PCA` - **Principal Component Analysis** is the No.1 technique that people use in data-science to accomplish this, to reduce the number of features.\n",
    "\n",
    "The implementation of it via the code is easy, but behind the scenes, we can think about `PCA` like it is a **compressor**.\n",
    "\n",
    "So say, at the start we are having originally about 100 features and we are trying to compress them so that in the end, we get 10 new features. But the 10 new features are made up with some percentage of the _original feature one_, some percentage of the _original feature two_ and some percentage of _original feature three and so forth_.\n",
    "\n",
    "So, what we will be loosing there is that we will not be able to interpret the features as before, like the previous example, _number of bedrooms_ is a pretty easy to understand what it means as a feature, likely number of bathrooms or squareFootage etc.\n",
    "\n",
    "But, if we are saying that 20% is coming from bathrooms, 30% from bedrooms, the rest is coming from squareFootage and this is our _new feature number one_ then this is not so easy to understand what that it means. Rather on the flip-side, we can really avoid this _curse of dimensionality_ and really compress our feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Initial Setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns  # Library used to print nicer charts and visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>rooms</th>\n",
       "      <th>squareFootage</th>\n",
       "      <th>lotSize</th>\n",
       "      <th>yearBuilt</th>\n",
       "      <th>lastSaleDate</th>\n",
       "      <th>lastSaleAmount</th>\n",
       "      <th>priorSaleDate</th>\n",
       "      <th>priorSaleAmount</th>\n",
       "      <th>estimated_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39525749</td>\n",
       "      <td>8171 E 84th Ave</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>80022</td>\n",
       "      <td>39.84916</td>\n",
       "      <td>-104.893468</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1378</td>\n",
       "      <td>9968</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2009-12-17</td>\n",
       "      <td>75000</td>\n",
       "      <td>2004-05-13</td>\n",
       "      <td>165700.0</td>\n",
       "      <td>239753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184578398</td>\n",
       "      <td>10556 Wheeling St</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>80022</td>\n",
       "      <td>39.88802</td>\n",
       "      <td>-104.830930</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1653</td>\n",
       "      <td>6970</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>2004-09-23</td>\n",
       "      <td>216935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>343963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184430015</td>\n",
       "      <td>3190 Wadsworth Blvd</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>80033</td>\n",
       "      <td>39.76171</td>\n",
       "      <td>-105.081070</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1882</td>\n",
       "      <td>23875</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>2008-04-03</td>\n",
       "      <td>330000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>488840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155129946</td>\n",
       "      <td>3040 Wadsworth Blvd</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>80033</td>\n",
       "      <td>39.76078</td>\n",
       "      <td>-105.081060</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "      <td>11500</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>185000</td>\n",
       "      <td>2008-06-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>494073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id              address    city state  zipcode  latitude  \\\n",
       "0   39525749      8171 E 84th Ave  Denver    CO    80022  39.84916   \n",
       "1  184578398    10556 Wheeling St  Denver    CO    80022  39.88802   \n",
       "2  184430015  3190 Wadsworth Blvd  Denver    CO    80033  39.76171   \n",
       "3  155129946  3040 Wadsworth Blvd  Denver    CO    80033  39.76078   \n",
       "\n",
       "    longitude  bedrooms  bathrooms  rooms  squareFootage  lotSize  yearBuilt  \\\n",
       "0 -104.893468         3        2.0      6           1378     9968     2003.0   \n",
       "1 -104.830930         2        2.0      6           1653     6970     2004.0   \n",
       "2 -105.081070         3        1.0      0           1882    23875     1917.0   \n",
       "3 -105.081060         4        3.0      0           2400    11500     1956.0   \n",
       "\n",
       "  lastSaleDate  lastSaleAmount priorSaleDate  priorSaleAmount  estimated_value  \n",
       "0   2009-12-17           75000    2004-05-13         165700.0           239753  \n",
       "1   2004-09-23          216935           NaN              NaN           343963  \n",
       "2   2008-04-03          330000           NaN              NaN           488840  \n",
       "3   2008-12-02          185000    2008-06-27              0.0           494073  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'../../assets/single_family_home_values.csv')\n",
    "df.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>rooms</th>\n",
       "      <th>squareFootage</th>\n",
       "      <th>lotSize</th>\n",
       "      <th>yearBuilt</th>\n",
       "      <th>priorSaleAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1378</td>\n",
       "      <td>9968</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>165700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1653</td>\n",
       "      <td>6970</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1882</td>\n",
       "      <td>23875</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "      <td>11500</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2305</td>\n",
       "      <td>5600</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  rooms  squareFootage  lotSize  yearBuilt  \\\n",
       "0         3        2.0      6           1378     9968     2003.0   \n",
       "1         2        2.0      6           1653     6970     2004.0   \n",
       "2         3        1.0      0           1882    23875     1917.0   \n",
       "3         4        3.0      0           2400    11500     1956.0   \n",
       "4         3        4.0      8           2305     5600     1998.0   \n",
       "\n",
       "   priorSaleAmount  \n",
       "0         165700.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X will be all the columns, without estimated_value\n",
    "X = df.drop('estimated_value', axis=1)\n",
    "X = X[['bedrooms', 'bathrooms', 'rooms', 'squareFootage',\n",
    "       'lotSize', 'yearBuilt', 'priorSaleAmount']]\n",
    "X.fillna(0, inplace=True)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         239753\n",
       "1         343963\n",
       "2         488840\n",
       "3         494073\n",
       "4         513676\n",
       "          ...   \n",
       "14995    1080081\n",
       "14996     807306\n",
       "14997    1737156\n",
       "14998    2008794\n",
       "14999    1421401\n",
       "Name: estimated_value, Length: 15000, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.estimated_value\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PCA - Principal Component Analysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are declaring that we need **4 components**. We surely might not know this at the beginning so we might have to do some analysis or use elbow approach to determine where we need to stop and use that value.\n",
    "\n",
    "Finally, we need to have the new feature set lower than the original feature set. So, sometime we need to do a lot of trial and errors and other times we can look at Elbow plots to see what is the drop in the explained variance by adding a new feature _(increasing the count)_.\n",
    "\n",
    "So, that where we can customize and decide what number is best.\n",
    "\n",
    "Now, we have our `X`, our initial feature set, with 15000 rows and 7 columns and we'll take look at how we can use `PCA` to compress our feature set and get the new feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = pca.fit_transform(X) # This will fit and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we keep the same number of rows, but we have the columns _(features)_ reduced to 4.\n",
    "\n",
    "And now we can use a very useful function in `PCA`, **.components_**, will give the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.34835866e-07,  1.39033126e-06,  1.76645671e-06,\n",
       "         9.91884229e-04,  1.22556479e-03,  8.13159056e-06,\n",
       "         9.99998757e-01],\n",
       "       [ 4.59899754e-05,  8.88602690e-05,  1.02614970e-04,\n",
       "         9.51591022e-02,  9.95457158e-01,  2.83604230e-03,\n",
       "        -1.31440908e-03],\n",
       "       [-7.41279240e-04, -1.10361769e-03, -1.93477104e-03,\n",
       "        -9.95458475e-01,  9.51576074e-02,  1.08902953e-03,\n",
       "         8.70755249e-04],\n",
       "       [ 2.87494377e-03, -3.44585965e-03,  6.23055904e-03,\n",
       "        -8.24565322e-04,  2.92725018e-03, -9.99965895e-01,\n",
       "         5.35419321e-06]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shape of .components\n",
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of **.components_** says 4x7, meaning we have 4 components and each of these components is made up by the original 7 components.\n",
    "\n",
    "Let's look at the first component, the first new feature that we have after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.34835866e-07, 1.39033126e-06, 1.76645671e-06, 9.91884229e-04,\n",
       "       1.22556479e-03, 8.13159056e-06, 9.99998757e-01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first new feature\n",
    "pca.components_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this new component has **seven members**, meaning these are the weights that we assigned to the original feature.\n",
    "\n",
    "That is, 0 element is the weight assigned to the original feature 0 etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7348404575064864"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, comparing to the previous result using the LinearRegression value **0.7580178906271744**, we see that this is almost the same compared to this **transformed feature-set**.\n",
    "\n",
    "We can say that we actually did not need `PCA` as in fact we only have 7 features and it's really not a lot of features.\n",
    "\n",
    "But, if in case we were using our original dataset, which had a lot of fields (excluding the prediction variable), then may be `PCA` could have been a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Conclusion`\n",
    "\n",
    "---\n",
    "[next]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b4484ae063bf9ef0d5115063857dd0e382a2c73ed49a11a000ca56af03302b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
